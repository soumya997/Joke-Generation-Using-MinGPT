{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/short-jokes/shortjokes.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!git clone https://github.com/kamalkraj/minGPT-TF.git","execution_count":5,"outputs":[{"output_type":"stream","text":"Cloning into 'minGPT-TF'...\nremote: Enumerating objects: 64, done.\u001b[K\nremote: Counting objects: 100% (64/64), done.\u001b[K\nremote: Compressing objects: 100% (44/44), done.\u001b[K\nremote: Total 64 (delta 30), reused 45 (delta 17), pack-reused 0\u001b[K\nUnpacking objects: 100% (64/64), done.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd ./minGPT-TF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd \n# ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir('./minGPT-TF')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install fastprogress==0.2.3","execution_count":6,"outputs":[{"output_type":"stream","text":"Collecting fastprogress==0.2.3\n  Downloading fastprogress-0.2.3-py3-none-any.whl (12 kB)\nInstalling collected packages: fastprogress\n  Attempting uninstall: fastprogress\n    Found existing installation: fastprogress 1.0.0\n    Uninstalling fastprogress-1.0.0:\n      Successfully uninstalled fastprogress-1.0.0\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\nfastai 2.0.16 requires fastprogress>=0.2.4, but you'll have fastprogress 0.2.3 which is incompatible.\u001b[0m\nSuccessfully installed fastprogress-0.2.3\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport tensorflow as tf\nfrom mingpt.model import GPT, GPTConfig","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CharDataset:\n\n    def __init__(self, data, block_size):\n        chars = sorted(list(set(data)))\n        data_size, vocab_size = len(data), len(chars)\n        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n        \n        self.stoi = { ch:i for i,ch in enumerate(chars) }\n        self.itos = { i:ch for i,ch in enumerate(chars) }\n        self.block_size = block_size\n        self.vocab_size = vocab_size\n        self.data = data\n    \n    def __len__(self):\n        return math.ceil(len(self.data) / (self.block_size + 1))\n\n    def __iter__(self):\n        # we're actually going to \"cheat\" and pick a spot in the dataset at \n        for _ in range(self.__len__()):\n            i = np.random.randint(0, len(self.data) - (self.block_size + 1))\n            chunk = self.data[i:i+self.block_size+1]\n            dix = [self.stoi[s] for s in chunk]\n            x = tf.convert_to_tensor(dix[:-1], dtype=tf.int32)\n            y = tf.convert_to_tensor(dix[1:], dtype=tf.int32)\n            yield x, y\n    \n    __call__ = __iter__","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"block_size = 128 ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# text = open('input.txt', 'r').read()\n# train_dataset_gen = CharDataset(text, block_size) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dataset = tf.data.Dataset.from_generator(train_dataset_gen,(tf.int32,tf.int32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from mingpt.model import GPT, GPTConfig\n# mconf = GPTConfig(train_dataset_gen.vocab_size, train_dataset_gen.block_size,\n#                   n_layer=8, n_head=8, n_embd=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from mingpt.trainer import Trainer, TrainerConfig\n\n# # initialize a trainer instance and kick off training\n# tconf = TrainerConfig(max_epochs=10, batch_size=128, learning_rate=6e-4,\n#                       lr_decay=True, warmup_tokens=512*20, final_tokens=200*len(train_dataset_gen)*block_size,\n#                       num_workers=4)\n# trainer = Trainer(GPT, mconf, train_dataset, len(train_dataset_gen), None, None, tconf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainer.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # alright, let's sample some character-level\n# from mingpt.utils import sample\n\n# context = \"O God, O God!\"\n# x = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\n# y = sample(trainer.model, x, 2000, temperature=0.9, sample=True, top_k=5)[0]\n# completion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\n# print(completion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.chdir('/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ntxt = pd.read_csv('../input/short-jokes/shortjokes.csv')\ntxt.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   ID                                               Joke\n0   1  [me narrating a documentary about narrators] \"...\n1   2  Telling my daughter garlic is good for you. Go...\n2   3  I've been going through a really rough period ...\n3   4  If I could have dinner with anyone, dead or al...\n4   5     Two guys walk into a bar. The third guy ducks.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Joke</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[me narrating a documentary about narrators] \"...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Telling my daughter garlic is good for you. Go...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>I've been going through a really rough period ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>If I could have dinner with anyone, dead or al...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Two guys walk into a bar. The third guy ducks.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt1= []\n\nfor i in txt['Joke']:\n    txt1.append(i)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt2 = str(txt1)\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(txt2)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"str"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir('./minGPT-TF')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset_gen = CharDataset(txt2, block_size) ","execution_count":11,"outputs":[{"output_type":"stream","text":"data has 22508167 characters, 95 unique.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_generator(train_dataset_gen,(tf.int32,tf.int32))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mingpt.model import GPT, GPTConfig\nmconf = GPTConfig(train_dataset_gen.vocab_size, train_dataset_gen.block_size,\n                  n_layer=8, n_head=8, n_embd=512)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mingpt.trainer import Trainer, TrainerConfig\n\n\ntconf = TrainerConfig(max_epochs=10, batch_size=128, learning_rate=6e-4,\n                      lr_decay=True, warmup_tokens=512*20, final_tokens=200*len(train_dataset_gen)*block_size,\n                      num_workers=4)\ntrainer = Trainer(GPT, mconf, train_dataset, len(train_dataset_gen), None, None, tconf)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.train()","execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"stream","text":"epoch 1: train loss 231.14236. lr 5.999630e-04\nepoch 2: train loss 169.85301. lr 5.998520e-04\nepoch 3: train loss 158.83913. lr 5.996671e-04\nepoch 4: train loss 152.69626. lr 5.994082e-04\nepoch 5: train loss 148.66898. lr 5.990753e-04\nepoch 6: train loss 145.65729. lr 5.986688e-04\nepoch 7: train loss 143.14734. lr 5.981885e-04\nepoch 8: train loss 140.98088. lr 5.976346e-04\nepoch 9: train loss 139.33232. lr 5.970074e-04\nepoch 10: train loss 137.86714. lr 5.963068e-04\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"love\"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 500, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":21,"outputs":[{"output_type":"stream","text":"love the whole world of parenting is that I have anything to dry.\", \"I can never find out if anyone will show up that into the field that isn't asking for some time... That isn't my favorite currency in my family.\", \"How do you make hormone a black man fly in a vending man? You don't have to see if he wants to check his mind out!\", 'What do you call a gay girl? Sir Cumference.', 'What do you call a guy in school? An elevator.', \"If you love something you can stand on a woman it's still there. If you\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"Tanul is crazy\"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 100, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":23,"outputs":[{"output_type":"stream","text":"Tanul is crazy if you can\\'t be a constant president in the bed is like a big penis... I don\\'t want to say anythi\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"There was no one\"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 90, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":25,"outputs":[{"output_type":"stream","text":"There was no one was gonna take a couple.', 'Two men walk into a bar. The one says, \"One is a straight man\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"How do you feel when you lie to me\"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 64, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":26,"outputs":[{"output_type":"stream","text":"How do you feel when you lie to me? Your mom.', 'What do you call a gay man? A baby in a stranger'\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"You are a Dick \"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 64, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":27,"outputs":[{"output_type":"stream","text":"You are a Dickshell, but I don't want to be a giraffe. Worried that I don't th\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"That cat \"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 64, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":28,"outputs":[{"output_type":"stream","text":"That cat show.\"', 'How do I take the toilet? Wait, in they stand up and p\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"This is fucking insane\"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 64, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":29,"outputs":[{"output_type":"stream","text":"This is fucking insane.\", 'What do you call a cheap girl with no fingers? Massive.', '\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom mingpt.utils import sample\n\ncontext = \"I can crack jokes do you want \"\nx = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\ny = sample(trainer.model, x, 100, temperature=0.9, sample=True, top_k=5)[0]\ncompletion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\nprint(completion)","execution_count":32,"outputs":[{"output_type":"stream","text":"I can crack jokes do you want to become an Asian girl who's had a hard time making a sense of humor.\", \"Why do the birds always wa\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}